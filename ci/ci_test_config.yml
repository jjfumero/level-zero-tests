# CI Test Configuration
#
# This file allows custom tests and custom test configurations to be included
# and applied on top of any auto-detected google tests. The top-level is a list
# of dictionaries mapping either a full name of a test or a test name wildcard
# pattern to a configuration. Any entry without wildcards is considered a custom
# test, and any entry containing wildcards ('*') will be applied to all tests
# (custom or otherwise) whose name matches the pattern. Pattern matching allows
# configurations to be applied broadly.
#
# For multiple entries which specify the same configuration items for a test,
# the last one takes precedence.
#
# Each entry may specify several configuration items:
# - timeout: Seconds that the test should be allowed to run before being
#       considered stalled.
# - executable: The name of the executable containing the test.
# - args: List of strings to pass to the executable to run this and only this
#       test.
# - regression: Dictionary mapping modes to lists of platforms (product
#       families) that should be run by ci-regression.py in each mode.
# - publish-aubs: List of platforms for which AUBs should be generated by
#       ci-generate-aubs.py and published.

---
- '*':
    timeout: 60
    regression:
      fulsim: ["skl"]
    publish-aubs: ["skl", "ats"]

- xe_peak.global_bw:
    executable: xe_peak
    args: ["-t", "global_bw"]
  xe_peak.hp_compute:
    executable: xe_peak
    args: ["-t", "hp_compute"]
  xe_peak.sp_compute:
    executable: xe_peak
    args: ["-t", "sp_compute"]
  xe_peak.dp_compute:
    executable: xe_peak
    args: ["-t", "dp_compute"]
  xe_peak.int_compute:
    executable: xe_peak
    args: ["-t", "int_compute"]
  xe_peak.transfer_bw:
    executable: xe_peak
    args: ["-t", "transfer_bw"]
  xe_peak.kernel_lat:
    executable: xe_peak
    args: ["-t", "kernel_lat"]
  xe_peer:
    executable: xe_peer
    args: []

# Disable AUB publishing for perf tests because their AUB files are huge.
# Publishing their AUB files would require a housekeeping pipeline to go and
# delete old ones from artifactory.
- XeNano*:
    publish-aubs: []
  xe_peak*:
    publish-aubs: []
  xe_peer:
    publish-aubs: []

# HACK: Disable regression execution for perf tests because the current timeout
# implementation is very naive, and running the perf tests in AUB mode uses too
# much CPU for every test to complete after their timeout. Rather than raising
# the timeout, I'm disabling the perf tests to be run in this mode until a
# timeout implementation (e.g., measures CPU time rather than wallclock time)
# is available.
- XeNano*:
    regression: {}
  xe_peak*:
    regression: {}
  xe_peer:
    regression: {}
...
